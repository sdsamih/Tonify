{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Função para receber o gênero de uma música do dataset de acordo com seu ID"
      ],
      "metadata": {
        "id": "beC8RuTq3r4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def check_gender_by_id(filename, id, genders) -> None | str:\n",
        "    df = pd.read_excel(filename)\n",
        "\n",
        "    genero = df.loc[df['id'] == id, 'genero']\n",
        "\n",
        "    if not genero.empty:\n",
        "        if genero.iloc[0] in genders:\n",
        "            return genero.iloc[0]\n",
        "        else:\n",
        "            return None\n",
        "    else:\n",
        "        return \"ID not found\""
      ],
      "metadata": {
        "id": "ZzsmvSSe32Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de uso\n",
        "arquivo = '/content/generos.xlsx'\n",
        "id_musica = 17  # Coloque o ID desejado\n",
        "genders = ['Rock', 'Jazz', 'Pop', 'Classical', 'Country', 'Eletronical']\n",
        "genero = check_gender_by_id(arquivo, id_musica, genders)\n",
        "print(f'O gênero da música com ID {id_musica} é: {genero}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTaTYkMQ51hM",
        "outputId": "183d6836-0d45-4ef1-fc36-d61c7f8a3de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O gênero da música com ID 17 é: Rock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dividir_musicas_em_listas(arquivo_xlsx, generos_validos):\n",
        "    # Carrega o arquivo Excel para um DataFrame\n",
        "    df = pd.read_excel(arquivo_xlsx)\n",
        "\n",
        "    # Dicionário para armazenar as músicas de cada gênero\n",
        "    generos = {}\n",
        "\n",
        "    # Itera por todas as músicas no arquivo\n",
        "    for id_musica in df['id']:\n",
        "        # Usa a função check_gender_by_id para obter o gênero da música\n",
        "        genero = check_gender_by_id(arquivo_xlsx, id_musica, generos_validos)\n",
        "\n",
        "        # Se o gênero for válido (não None e dentro da lista de gêneros válidos), adiciona o ID\n",
        "        if genero and genero in generos_validos:\n",
        "            if genero not in generos:\n",
        "                generos[genero] = []\n",
        "            generos[genero].append(id_musica)\n",
        "\n",
        "    # Listas para armazenar as músicas de treino, validação e teste\n",
        "    musicas_treino = []\n",
        "    musicas_validacao = []\n",
        "    musicas_teste = []\n",
        "\n",
        "    # Agora, vamos dividir as músicas por gênero em treino, validação e teste de forma aleatória\n",
        "    for genero, musicas in generos.items():\n",
        "        # Embaralha as músicas para aleatoriedade\n",
        "        random.shuffle(musicas)\n",
        "\n",
        "        # Verifica se há pelo menos 30 músicas para dividir\n",
        "        if len(musicas) >= 30:\n",
        "            # Divide as músicas de forma aleatória\n",
        "            treino = musicas[:21]\n",
        "            validacao = musicas[21:27]\n",
        "            teste = musicas[27:30]\n",
        "\n",
        "            # Adiciona as listas para cada categoria\n",
        "            musicas_treino.extend(treino)\n",
        "            musicas_validacao.extend(validacao)\n",
        "            musicas_teste.extend(teste)\n",
        "        else:\n",
        "            # Se houver menos de 30 músicas, podemos decidir o que fazer, mas aqui estamos ignorando as músicas\n",
        "            pass\n",
        "\n",
        "    # Retorna as 3 listas\n",
        "    return musicas_treino, musicas_validacao, musicas_teste"
      ],
      "metadata": {
        "id": "9j_nOG1e9W94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "treino,validacao,teste = dividir_musicas_em_listas('/content/generos.xlsx',genders)"
      ],
      "metadata": {
        "id": "neDvYuGb9bHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in treino:\n",
        "  print(check_gender_by_id('/content/generos.xlsx',x,genders))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z1jih8o90tc",
        "outputId": "b5422e1e-6467-4084-bab3-64aedef46393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RSJULw20Yse7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/espectrogramas.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-q7bx-IYkXi",
        "outputId": "40dc13af-e6b4-444e-ef00-ca22be89ad81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/espectrogramas.zip\n",
            "replace espectrogramas/238.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: espectrogramas/238.png  \n",
            "  inflating: espectrogramas/182.png  \n",
            "  inflating: espectrogramas/150.png  \n",
            "  inflating: espectrogramas/15.png   \n",
            "  inflating: espectrogramas/130.png  \n",
            "  inflating: espectrogramas/138.png  \n",
            "  inflating: espectrogramas/231.png  \n",
            "  inflating: espectrogramas/208.png  \n",
            "  inflating: espectrogramas/249.png  \n",
            "  inflating: espectrogramas/88.png   \n",
            "  inflating: espectrogramas/216.png  \n",
            "  inflating: espectrogramas/180.png  \n",
            "  inflating: espectrogramas/178.png  \n",
            "  inflating: espectrogramas/190.png  \n",
            "  inflating: espectrogramas/206.png  \n",
            "  inflating: espectrogramas/93.png   \n",
            "  inflating: espectrogramas/137.png  \n",
            "  inflating: espectrogramas/115.png  \n",
            "  inflating: espectrogramas/28.png   \n",
            "  inflating: espectrogramas/23.png   \n",
            "  inflating: espectrogramas/84.png   \n",
            "  inflating: espectrogramas/118.png  \n",
            "  inflating: espectrogramas/52.png   \n",
            "  inflating: espectrogramas/185.png  \n",
            "  inflating: espectrogramas/147.png  \n",
            "  inflating: espectrogramas/223.png  \n",
            "  inflating: espectrogramas/111.png  \n",
            "  inflating: espectrogramas/1.png    \n",
            "  inflating: espectrogramas/82.png   \n",
            "  inflating: espectrogramas/81.png   \n",
            "  inflating: espectrogramas/141.png  \n",
            "  inflating: espectrogramas/100.png  \n",
            "  inflating: espectrogramas/10.png   \n",
            "  inflating: espectrogramas/85.png   \n",
            "  inflating: espectrogramas/21.png   \n",
            "  inflating: espectrogramas/131.png  \n",
            "  inflating: espectrogramas/125.png  \n",
            "  inflating: espectrogramas/86.png   \n",
            "  inflating: espectrogramas/48.png   \n",
            "  inflating: espectrogramas/248.png  \n",
            "  inflating: espectrogramas/142.png  \n",
            "  inflating: espectrogramas/154.png  \n",
            "  inflating: espectrogramas/133.png  \n",
            "  inflating: espectrogramas/202.png  \n",
            "  inflating: espectrogramas/63.png   \n",
            "  inflating: espectrogramas/17.png   \n",
            "  inflating: espectrogramas/29.png   \n",
            "  inflating: espectrogramas/173.png  \n",
            "  inflating: espectrogramas/250.png  \n",
            "  inflating: espectrogramas/175.png  \n",
            "  inflating: espectrogramas/196.png  \n",
            "  inflating: espectrogramas/31.png   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo: Gêneros associados aos IDs\n",
        "id_to_genre = {\n",
        "    1: \"Rock\",\n",
        "    2: \"Pop\",\n",
        "    3: \"Jazz\",\n",
        "    4: \"Eletronical\",\n",
        "    5: \"Classical\",\n",
        "    6: \"Country\"\n",
        "    # Adicione todos os IDs e seus gêneros\n",
        "}\n",
        "\n",
        "# Converta os gêneros para índices numéricos para o treinamento\n",
        "genre_to_index = {genre: idx for idx, genre in enumerate(set(id_to_genre.values()))}\n",
        "\n",
        "# Exemplo: rock -> 0, pop -> 1, jazz -> 2\n",
        "id_to_label = {id: genre_to_index[genre] for id, genre in id_to_genre.items()}\n"
      ],
      "metadata": {
        "id": "UgWIruqaplcZ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "\n",
        "base_dir = \"/content/espectrogramas\"\n",
        "\n",
        "def id_to_filepath(id):\n",
        "  return os.path.join(base_dir,f\"{id}.png\")"
      ],
      "metadata": {
        "id": "p2G9EJ80XlH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/generos.xlsx')\n",
        "\n",
        "# Cria o mapeamento de gêneros para índices\n",
        "genre_to_index = {genre: idx for idx, genre in enumerate(set(df['genero']))}\n",
        "\n",
        "# Mapeia IDs das músicas aos índices das classes\n",
        "id_to_label = {row['id']: genre_to_index[row['genero']] for _, row in df.iterrows()}\n",
        "\n",
        "print(\"id_to_label:\", id_to_label)"
      ],
      "metadata": {
        "id": "J0k7ixp6sOQq",
        "outputId": "943eed36-30f7-42fd-d347-bde5d7220ab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id_to_label: {1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 6, 12: 6, 13: 6, 14: 6, 15: 6, 16: 6, 17: 6, 18: 6, 19: 6, 20: 6, 21: 7, 22: 7, 23: 7, 24: 7, 25: 7, 26: 7, 27: 7, 28: 7, 29: 7, 30: 7, 31: 4, 32: 4, 33: 4, 34: 4, 35: 4, 36: 4, 37: 4, 38: 4, 39: 4, 40: 4, 41: 2, 42: 2, 43: 2, 44: 2, 45: 2, 46: 2, 47: 2, 48: 2, 49: 2, 50: 2, 51: 5, 52: 5, 53: 5, 54: 5, 55: 5, 56: 5, 57: 5, 58: 5, 59: 5, 60: 5, 61: 3, 62: 3, 63: 3, 64: 3, 65: 3, 66: 3, 67: 3, 68: 3, 69: 3, 70: 3, 71: 10, 72: 10, 73: 10, 74: 10, 75: 10, 76: 10, 77: 10, 78: 10, 79: 10, 80: 10, 81: 0, 82: 0, 83: 0, 84: 0, 85: 0, 86: 0, 87: 0, 88: 0, 89: 0, 90: 0, 91: 8, 92: 8, 93: 8, 94: 8, 95: 8, 96: 8, 97: 8, 98: 8, 99: 8, 100: 8, 101: 9, 102: 9, 103: 9, 104: 9, 105: 9, 106: 9, 107: 9, 108: 9, 109: 9, 110: 9, 111: 1, 112: 1, 113: 1, 114: 1, 115: 1, 116: 1, 117: 1, 118: 1, 119: 1, 120: 1, 121: 1, 122: 1, 123: 1, 124: 1, 125: 1, 126: 1, 127: 1, 128: 1, 129: 1, 130: 1, 131: 6, 132: 6, 133: 6, 134: 6, 135: 6, 136: 6, 137: 6, 138: 6, 139: 6, 140: 6, 141: 6, 142: 6, 143: 6, 144: 6, 145: 6, 146: 6, 147: 6, 148: 6, 149: 6, 150: 6, 151: 4, 152: 4, 153: 4, 154: 4, 155: 4, 156: 4, 157: 4, 158: 4, 159: 4, 160: 4, 161: 4, 162: 4, 163: 4, 164: 4, 165: 4, 166: 4, 167: 4, 168: 4, 169: 4, 170: 4, 171: 2, 172: 2, 173: 2, 174: 2, 175: 2, 176: 2, 177: 2, 178: 2, 179: 2, 180: 2, 181: 2, 182: 2, 183: 2, 184: 2, 185: 2, 186: 2, 187: 2, 188: 2, 189: 2, 190: 2, 191: 5, 192: 5, 193: 5, 194: 5, 195: 5, 196: 5, 197: 5, 198: 5, 199: 5, 200: 5, 201: 5, 202: 5, 203: 5, 204: 5, 205: 5, 206: 5, 207: 5, 208: 5, 209: 5, 210: 5, 211: 0, 212: 0, 213: 0, 214: 0, 215: 0, 216: 0, 217: 0, 218: 0, 219: 0, 220: 0, 221: 0, 222: 0, 223: 0, 224: 0, 225: 0, 226: 0, 227: 0, 228: 0, 229: 0, 230: 0, 231: 8, 232: 8, 233: 8, 234: 8, 235: 8, 236: 8, 237: 8, 238: 8, 239: 8, 240: 8, 241: 8, 242: 8, 243: 8, 244: 8, 245: 8, 246: 8, 247: 8, 248: 8, 249: 8, 250: 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf_dataset_with_labels(id_list, id_to_label):\n",
        "    filepaths = [id_to_filepath(id) for id in id_list]\n",
        "    labels = [id_to_label[id] for id in id_list]\n",
        "\n",
        "    # Cria um dataset contendo pares (caminho, rótulo)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
        "\n",
        "    # Carrega a imagem e retorna (imagem, rótulo)\n",
        "    def load_image_and_label(filepath, label):\n",
        "        image = tf.io.read_file(filepath)\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "        image = tf.image.resize(image, [224, 224])  # Tamanho esperado pela CNN\n",
        "        return image, label\n",
        "\n",
        "    dataset = dataset.map(load_image_and_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "fzZv2aEkp-LD"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = create_tf_dataset_with_labels(treino, id_to_label)\n",
        "val_dataset = create_tf_dataset_with_labels(validacao, id_to_label)\n",
        "test_dataset = create_tf_dataset_with_labels(teste, id_to_label)\n",
        "\n",
        "# Agrupar em lotes e otimizar\n",
        "batch_size = 32\n",
        "train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "NQukVDdAp_Ss"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "\n",
        "img = cv.imread(\"/content/espectrogramas/125.png\")\n",
        "\n",
        "\n",
        "input_shape = img.shape\n",
        "num_classes = len(set(id_to_label.values()))\n",
        "print(f\"Quantidade de classes: {num_classes}\")\n",
        "\n",
        "print(num_classes)"
      ],
      "metadata": {
        "id": "CHphZmmBvvSV",
        "outputId": "c4cec5ff-7fc1-4b17-9292-2661f72bc779",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de classes: 11\n",
            "11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2))\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dropout(0.5))\n",
        "cnn.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
        "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-wHN_xuttVH_",
        "outputId": "644622f6-f09d-4934-fcd6-28fccb220b31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = cnn.fit(train_dataset, epochs=30, validation_data=val_dataset)"
      ],
      "metadata": {
        "id": "al5feFF0tUmU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "13254cc9-0a7e-4500-b17b-7a11621b1022"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_1\" is incompatible with the layer: expected axis -1 of input shape to have value 4165632, but received input with shape (None, 86528)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 224, 224, 3), dtype=float32)\n  • training=True\n  • mask=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-5ae97457ee36>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 }:\n\u001b[0;32m--> 227\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    228\u001b[0m                         \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                         \u001b[0;34mf\"incompatible with the layer: expected axis {axis} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_1\" is incompatible with the layer: expected axis -1 of input shape to have value 4165632, but received input with shape (None, 86528)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 224, 224, 3), dtype=float32)\n  • training=True\n  • mask=None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5kiKSxtf0_Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xNSqY7iA0Ru0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VdW1GUdgtUdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ipLMuBgRtUUG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}