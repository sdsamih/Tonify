{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Importação das bibliotecas**"
      ],
      "metadata": {
        "id": "M__QbgdQbHVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "OjvfXclHKudA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e92a1cb-94e0-4a67-c263-a478d4bed287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/trab_IA/dataset_espectro.zip"
      ],
      "metadata": {
        "id": "jJ5yOjZNK2j3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89c178d0-69d4-4fc7-caa6-72d3cc68583e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/trab_IA/dataset_espectro.zip\n",
            "   creating: dataset_espectro/\n",
            "   creating: dataset_espectro/test/\n",
            "   creating: dataset_espectro/test/Blues/\n",
            "  inflating: dataset_espectro/test/Blues/108.png  \n",
            "   creating: dataset_espectro/test/Classical/\n",
            "  inflating: dataset_espectro/test/Classical/59.png  \n",
            "   creating: dataset_espectro/test/Country/\n",
            "  inflating: dataset_espectro/test/Country/93.png  \n",
            "   creating: dataset_espectro/test/Eletronical/\n",
            "  inflating: dataset_espectro/test/Eletronical/47.png  \n",
            "   creating: dataset_espectro/test/Folk/\n",
            "  inflating: dataset_espectro/test/Folk/75.png  \n",
            "   creating: dataset_espectro/test/Hip Hop/\n",
            "  inflating: dataset_espectro/test/Hip Hop/62.png  \n",
            "   creating: dataset_espectro/test/Instrumental/\n",
            "  inflating: dataset_espectro/test/Instrumental/6.png  \n",
            "   creating: dataset_espectro/test/Jazz/\n",
            "  inflating: dataset_espectro/test/Jazz/87.png  \n",
            "   creating: dataset_espectro/test/Pop/\n",
            "  inflating: dataset_espectro/test/Pop/33.png  \n",
            "   creating: dataset_espectro/test/Rock/\n",
            "  inflating: dataset_espectro/test/Rock/14.png  \n",
            "   creating: dataset_espectro/test/Soul/\n",
            "  inflating: dataset_espectro/test/Soul/28.png  \n",
            "   creating: dataset_espectro/train/\n",
            "   creating: dataset_espectro/train/Blues/\n",
            "  inflating: dataset_espectro/train/Blues/101.png  \n",
            "  inflating: dataset_espectro/train/Blues/102.png  \n",
            "  inflating: dataset_espectro/train/Blues/103.png  \n",
            "  inflating: dataset_espectro/train/Blues/105.png  \n",
            "  inflating: dataset_espectro/train/Blues/107.png  \n",
            "  inflating: dataset_espectro/train/Blues/109.png  \n",
            "  inflating: dataset_espectro/train/Blues/110.png  \n",
            "   creating: dataset_espectro/train/Classical/\n",
            "  inflating: dataset_espectro/train/Classical/52.png  \n",
            "  inflating: dataset_espectro/train/Classical/53.png  \n",
            "  inflating: dataset_espectro/train/Classical/54.png  \n",
            "  inflating: dataset_espectro/train/Classical/55.png  \n",
            "  inflating: dataset_espectro/train/Classical/56.png  \n",
            "  inflating: dataset_espectro/train/Classical/57.png  \n",
            "  inflating: dataset_espectro/train/Classical/60.png  \n",
            "   creating: dataset_espectro/train/Country/\n",
            "  inflating: dataset_espectro/train/Country/100.png  \n",
            "  inflating: dataset_espectro/train/Country/91.png  \n",
            "  inflating: dataset_espectro/train/Country/94.png  \n",
            "  inflating: dataset_espectro/train/Country/95.png  \n",
            "  inflating: dataset_espectro/train/Country/96.png  \n",
            "  inflating: dataset_espectro/train/Country/97.png  \n",
            "  inflating: dataset_espectro/train/Country/99.png  \n",
            "   creating: dataset_espectro/train/Eletronical/\n",
            "  inflating: dataset_espectro/train/Eletronical/41.png  \n",
            "  inflating: dataset_espectro/train/Eletronical/42.png  \n",
            "  inflating: dataset_espectro/train/Eletronical/43.png  \n",
            "  inflating: dataset_espectro/train/Eletronical/45.png  \n",
            "  inflating: dataset_espectro/train/Eletronical/46.png  \n",
            "  inflating: dataset_espectro/train/Eletronical/48.png  \n",
            "  inflating: dataset_espectro/train/Eletronical/50.png  \n",
            "   creating: dataset_espectro/train/Folk/\n",
            "  inflating: dataset_espectro/train/Folk/71.png  \n",
            "  inflating: dataset_espectro/train/Folk/72.png  \n",
            "  inflating: dataset_espectro/train/Folk/73.png  \n",
            "  inflating: dataset_espectro/train/Folk/76.png  \n",
            "  inflating: dataset_espectro/train/Folk/77.png  \n",
            "  inflating: dataset_espectro/train/Folk/78.png  \n",
            "  inflating: dataset_espectro/train/Folk/79.png  \n",
            "   creating: dataset_espectro/train/Hip Hop/\n",
            "  inflating: dataset_espectro/train/Hip Hop/63.png  \n",
            "  inflating: dataset_espectro/train/Hip Hop/65.png  \n",
            "  inflating: dataset_espectro/train/Hip Hop/66.png  \n",
            "  inflating: dataset_espectro/train/Hip Hop/67.png  \n",
            "  inflating: dataset_espectro/train/Hip Hop/68.png  \n",
            "  inflating: dataset_espectro/train/Hip Hop/69.png  \n",
            "  inflating: dataset_espectro/train/Hip Hop/70.png  \n",
            "   creating: dataset_espectro/train/Instrumental/\n",
            "  inflating: dataset_espectro/train/Instrumental/1.png  \n",
            "  inflating: dataset_espectro/train/Instrumental/2.png  \n",
            "  inflating: dataset_espectro/train/Instrumental/3.png  \n",
            "  inflating: dataset_espectro/train/Instrumental/4.png  \n",
            "  inflating: dataset_espectro/train/Instrumental/7.png  \n",
            "  inflating: dataset_espectro/train/Instrumental/8.png  \n",
            "  inflating: dataset_espectro/train/Instrumental/9.png  \n",
            "   creating: dataset_espectro/train/Jazz/\n",
            "  inflating: dataset_espectro/train/Jazz/81.png  \n",
            "  inflating: dataset_espectro/train/Jazz/83.png  \n",
            "  inflating: dataset_espectro/train/Jazz/85.png  \n",
            "  inflating: dataset_espectro/train/Jazz/86.png  \n",
            "  inflating: dataset_espectro/train/Jazz/88.png  \n",
            "  inflating: dataset_espectro/train/Jazz/89.png  \n",
            "  inflating: dataset_espectro/train/Jazz/90.png  \n",
            "   creating: dataset_espectro/train/Pop/\n",
            "  inflating: dataset_espectro/train/Pop/31.png  \n",
            "  inflating: dataset_espectro/train/Pop/35.png  \n",
            "  inflating: dataset_espectro/train/Pop/36.png  \n",
            "  inflating: dataset_espectro/train/Pop/37.png  \n",
            "  inflating: dataset_espectro/train/Pop/38.png  \n",
            "  inflating: dataset_espectro/train/Pop/39.png  \n",
            "  inflating: dataset_espectro/train/Pop/40.png  \n",
            "   creating: dataset_espectro/train/Rock/\n",
            "  inflating: dataset_espectro/train/Rock/11.png  \n",
            "  inflating: dataset_espectro/train/Rock/12.png  \n",
            "  inflating: dataset_espectro/train/Rock/13.png  \n",
            "  inflating: dataset_espectro/train/Rock/15.png  \n",
            "  inflating: dataset_espectro/train/Rock/17.png  \n",
            "  inflating: dataset_espectro/train/Rock/19.png  \n",
            "  inflating: dataset_espectro/train/Rock/20.png  \n",
            "   creating: dataset_espectro/train/Soul/\n",
            "  inflating: dataset_espectro/train/Soul/22.png  \n",
            "  inflating: dataset_espectro/train/Soul/23.png  \n",
            "  inflating: dataset_espectro/train/Soul/25.png  \n",
            "  inflating: dataset_espectro/train/Soul/26.png  \n",
            "  inflating: dataset_espectro/train/Soul/27.png  \n",
            "  inflating: dataset_espectro/train/Soul/29.png  \n",
            "  inflating: dataset_espectro/train/Soul/30.png  \n",
            "   creating: dataset_espectro/val/\n",
            "   creating: dataset_espectro/val/Blues/\n",
            "  inflating: dataset_espectro/val/Blues/104.png  \n",
            "  inflating: dataset_espectro/val/Blues/106.png  \n",
            "   creating: dataset_espectro/val/Classical/\n",
            "  inflating: dataset_espectro/val/Classical/51.png  \n",
            "  inflating: dataset_espectro/val/Classical/58.png  \n",
            "   creating: dataset_espectro/val/Country/\n",
            "  inflating: dataset_espectro/val/Country/92.png  \n",
            "  inflating: dataset_espectro/val/Country/98.png  \n",
            "   creating: dataset_espectro/val/Eletronical/\n",
            "  inflating: dataset_espectro/val/Eletronical/44.png  \n",
            "  inflating: dataset_espectro/val/Eletronical/49.png  \n",
            "   creating: dataset_espectro/val/Folk/\n",
            "  inflating: dataset_espectro/val/Folk/74.png  \n",
            "  inflating: dataset_espectro/val/Folk/80.png  \n",
            "   creating: dataset_espectro/val/Hip Hop/\n",
            "  inflating: dataset_espectro/val/Hip Hop/61.png  \n",
            "  inflating: dataset_espectro/val/Hip Hop/64.png  \n",
            "   creating: dataset_espectro/val/Instrumental/\n",
            "  inflating: dataset_espectro/val/Instrumental/10.png  \n",
            "  inflating: dataset_espectro/val/Instrumental/5.png  \n",
            "   creating: dataset_espectro/val/Jazz/\n",
            "  inflating: dataset_espectro/val/Jazz/82.png  \n",
            "  inflating: dataset_espectro/val/Jazz/84.png  \n",
            "   creating: dataset_espectro/val/Pop/\n",
            "  inflating: dataset_espectro/val/Pop/32.png  \n",
            "  inflating: dataset_espectro/val/Pop/34.png  \n",
            "   creating: dataset_espectro/val/Rock/\n",
            "  inflating: dataset_espectro/val/Rock/16.png  \n",
            "  inflating: dataset_espectro/val/Rock/18.png  \n",
            "   creating: dataset_espectro/val/Soul/\n",
            "  inflating: dataset_espectro/val/Soul/21.png  \n",
            "  inflating: dataset_espectro/val/Soul/24.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Criação da Rede Neural Convolucional**"
      ],
      "metadata": {
        "id": "eLg84m-PmO-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Inicializando a CNN**"
      ],
      "metadata": {
        "id": "vILAF-ocmbkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "u2YYZv77q4FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pré-processamento\n"
      ],
      "metadata": {
        "id": "2owh3j8H7aE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/dataset_espectro/train\"\n",
        "test_dir = \"/content/dataset_espectro/test\"\n",
        "val_dir = \"/content/dataset_espectro/val\""
      ],
      "metadata": {
        "id": "6v7B4Jse4GYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255)"
      ],
      "metadata": {
        "id": "ad37kWGz7Xwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(400,1000),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sVeMJMq8I5b",
        "outputId": "3ed4d3fe-25bb-46d6-b7b5-dfdb249324a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 77 images belonging to 11 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_gen = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(400,1000),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPr0miFr8mEf",
        "outputId": "ea5f505e-3959-461b-931d-85c94493ac71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22 images belonging to 11 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(400,1000),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BALIyka081rV",
        "outputId": "572c6e21-ea58-4a10-9e96-12fb4d408e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11 images belonging to 11 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = [400,1000,3]\n",
        "num_classes = len(train_gen.class_indices)"
      ],
      "metadata": {
        "id": "Na84xJyB9K5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##O modelo em si\n"
      ],
      "metadata": {
        "id": "oPaDmL-q7gqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "Vi7PnE9Tmfs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2))"
      ],
      "metadata": {
        "id": "0awa2J5lmy22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2))"
      ],
      "metadata": {
        "id": "XwX7cOm2tiVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "HZ11geN3nBCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dropout(0.5))"
      ],
      "metadata": {
        "id": "Y_4ub3XBnGaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "rv5CM5qat5ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nTtHnSYEoLZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Treinando a CNN e estimando no conjunto de testes**"
      ],
      "metadata": {
        "id": "Ewn2dEtao0la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = cnn.fit(train_gen, epochs=30, validation_data=val_gen)"
      ],
      "metadata": {
        "id": "4jNTpdsLoQxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75541f1a-a736-41d4-8cd9-487eca709e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 36s/step - accuracy: 0.1189 - loss: 39.5148 - val_accuracy: 0.0909 - val_loss: 14.1094\n",
            "Epoch 2/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 25s/step - accuracy: 0.0637 - loss: 16.3326 - val_accuracy: 0.0909 - val_loss: 2.4451\n",
            "Epoch 3/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 35s/step - accuracy: 0.0491 - loss: 2.6196 - val_accuracy: 0.0909 - val_loss: 2.3553\n",
            "Epoch 4/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 35s/step - accuracy: 0.1622 - loss: 2.3842 - val_accuracy: 0.0909 - val_loss: 2.3484\n",
            "Epoch 5/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 35s/step - accuracy: 0.1425 - loss: 2.3301 - val_accuracy: 0.0909 - val_loss: 2.2953\n",
            "Epoch 6/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 26s/step - accuracy: 0.1685 - loss: 2.1613 - val_accuracy: 0.2727 - val_loss: 2.2871\n",
            "Epoch 7/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 26s/step - accuracy: 0.2581 - loss: 2.0095 - val_accuracy: 0.2273 - val_loss: 2.2197\n",
            "Epoch 8/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 25s/step - accuracy: 0.3524 - loss: 1.7990 - val_accuracy: 0.2727 - val_loss: 2.1360\n",
            "Epoch 9/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 26s/step - accuracy: 0.4799 - loss: 1.5590 - val_accuracy: 0.3182 - val_loss: 2.1345\n",
            "Epoch 10/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 25s/step - accuracy: 0.3696 - loss: 1.6456 - val_accuracy: 0.1818 - val_loss: 2.2433\n",
            "Epoch 11/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 34s/step - accuracy: 0.6035 - loss: 1.2472 - val_accuracy: 0.2727 - val_loss: 2.1371\n",
            "Epoch 12/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 35s/step - accuracy: 0.5602 - loss: 1.3336 - val_accuracy: 0.1364 - val_loss: 2.5075\n",
            "Epoch 13/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 34s/step - accuracy: 0.6410 - loss: 0.9941 - val_accuracy: 0.2273 - val_loss: 2.8887\n",
            "Epoch 14/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 35s/step - accuracy: 0.7374 - loss: 0.9099 - val_accuracy: 0.1818 - val_loss: 2.5349\n",
            "Epoch 15/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 35s/step - accuracy: 0.6832 - loss: 1.1379 - val_accuracy: 0.2727 - val_loss: 2.2727\n",
            "Epoch 16/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25s/step - accuracy: 0.7893 - loss: 0.7964 - val_accuracy: 0.4091 - val_loss: 2.3081\n",
            "Epoch 17/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 28s/step - accuracy: 0.7022 - loss: 0.7792 - val_accuracy: 0.4545 - val_loss: 2.3404\n",
            "Epoch 18/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 34s/step - accuracy: 0.7309 - loss: 0.7203 - val_accuracy: 0.3182 - val_loss: 2.5117\n",
            "Epoch 19/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 34s/step - accuracy: 0.8943 - loss: 0.4824 - val_accuracy: 0.2273 - val_loss: 2.5750\n",
            "Epoch 20/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 25s/step - accuracy: 0.8770 - loss: 0.4423 - val_accuracy: 0.3182 - val_loss: 2.6530\n",
            "Epoch 21/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 34s/step - accuracy: 0.8945 - loss: 0.3467 - val_accuracy: 0.3182 - val_loss: 2.8368\n",
            "Epoch 22/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 26s/step - accuracy: 0.8048 - loss: 0.4232 - val_accuracy: 0.2727 - val_loss: 3.4906\n",
            "Epoch 23/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 28s/step - accuracy: 0.8395 - loss: 0.6486 - val_accuracy: 0.3636 - val_loss: 2.8191\n",
            "Epoch 24/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 36s/step - accuracy: 0.9122 - loss: 0.4412 - val_accuracy: 0.3182 - val_loss: 2.8165\n",
            "Epoch 25/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 25s/step - accuracy: 0.8972 - loss: 0.4097 - val_accuracy: 0.3182 - val_loss: 3.0547\n",
            "Epoch 26/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 26s/step - accuracy: 0.8895 - loss: 0.3263 - val_accuracy: 0.2727 - val_loss: 3.5364\n",
            "Epoch 27/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25s/step - accuracy: 0.9473 - loss: 0.1784 - val_accuracy: 0.3182 - val_loss: 4.0412\n",
            "Epoch 28/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 26s/step - accuracy: 0.9154 - loss: 0.2506 - val_accuracy: 0.3182 - val_loss: 4.3104\n",
            "Epoch 29/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 25s/step - accuracy: 0.9274 - loss: 0.2057 - val_accuracy: 0.3182 - val_loss: 4.1862\n",
            "Epoch 30/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 25s/step - accuracy: 0.9610 - loss: 0.1189 - val_accuracy: 0.2273 - val_loss: 4.0148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = cnn.evaluate(test_gen)\n",
        "print(f\"Perda nos dados de teste: {test_loss}\")\n",
        "print(f\"Acurácia nos dados de teste: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "4FMd-MrZ99IT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "7da0c09e-78a7-498b-d155-77ef701547e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cnn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ae98a5650747>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Perda nos dados de teste: {test_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Acurácia nos dados de teste: {test_accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cnn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processar a imagem\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "test_image = image.load_img(\"/content/dataset_espectro/test/Eletronical/47.png\", target_size=(400, 1000))  # Tamanho da imagem usado no treinamento\n",
        "test_image = image.img_to_array(test_image)  # Converte a imagem para um array NumPy\n",
        "test_image = np.expand_dims(test_image, axis=0)  # Adiciona uma dimensão para o batch\n",
        "test_image = test_image"
      ],
      "metadata": {
        "id": "2Yhz5jq_Mw5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = cnn.predict(test_image)\n",
        "\n",
        "print(f\"Result: {result}\")\n",
        "\n",
        "predicted_class_index = np.argmax(result)  # Obtém o índice da classe com maior probabilidade\n",
        "print(f\"Predicted class index: {predicted_class_index}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY5o-Og4NIxF",
        "outputId": "852065dd-38d6-493e-ef4e-b253d290c5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step\n",
            "Result: [[1.0000000e+00 0.0000000e+00 3.3637510e-26 2.7023976e-25 0.0000000e+00\n",
            "  6.4744788e-27 4.5108618e-16 0.0000000e+00 4.1161588e-12 3.1795836e-29\n",
            "  8.2470836e-11]]\n",
            "Predicted class index: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dicionário de classes (gerado no treinamento)\n",
        "class_indices = {'rock': 0, 'jazz': 1, 'pop': 2, 'hip hop':3,'blues':4,'classical':5,'country':6,'eletronical':7,'folk':8,'instrumental':9,'soul':10}  # Substitua com as classes reais do treinamento\n",
        "index_to_class = {v: k for k, v in class_indices.items()}  # Converte índice para nome da classe\n",
        "\n",
        "# Obter o nome da classe prevista\n",
        "prediction = index_to_class[predicted_class_index]\n",
        "\n",
        "# Exibir o resultado\n",
        "print(f\"Predição: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ne6zns2NpqB",
        "outputId": "3baee4f5-44c5-41dd-8a66-7212d63d41f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predição: rock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função para receber o gênero de uma música do dataset de acordo com seu ID"
      ],
      "metadata": {
        "id": "beC8RuTq3r4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def check_gender_by_id(filename, id, genders) -> None | str:\n",
        "    df = pd.read_excel(filename)\n",
        "\n",
        "    genero = df.loc[df['id'] == id, 'genero']\n",
        "\n",
        "    if not genero.empty:\n",
        "        if genero.iloc[0] in genders:\n",
        "            return genero.iloc[0]\n",
        "        else:\n",
        "            return None\n",
        "    else:\n",
        "        return \"ID not found\""
      ],
      "metadata": {
        "id": "ZzsmvSSe32Dq"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de uso\n",
        "arquivo = '/content/generos.xlsx'\n",
        "id_musica = 17  # Coloque o ID desejado\n",
        "genders = ['Rock', 'Jazz', 'Pop', 'Classical', 'Country', 'Eletronical']\n",
        "genero = check_gender_by_id(arquivo, id_musica, genders)\n",
        "print(f'O gênero da música com ID {id_musica} é: {genero}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTaTYkMQ51hM",
        "outputId": "183d6836-0d45-4ef1-fc36-d61c7f8a3de1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O gênero da música com ID 17 é: Rock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dividir_musicas_em_listas(arquivo_xlsx, generos_validos):\n",
        "    # Carrega o arquivo Excel para um DataFrame\n",
        "    df = pd.read_excel(arquivo_xlsx)\n",
        "\n",
        "    # Dicionário para armazenar as músicas de cada gênero\n",
        "    generos = {}\n",
        "\n",
        "    # Itera por todas as músicas no arquivo\n",
        "    for id_musica in df['id']:\n",
        "        # Usa a função check_gender_by_id para obter o gênero da música\n",
        "        genero = check_gender_by_id(arquivo_xlsx, id_musica, generos_validos)\n",
        "\n",
        "        # Se o gênero for válido (não None e dentro da lista de gêneros válidos), adiciona o ID\n",
        "        if genero and genero in generos_validos:\n",
        "            if genero not in generos:\n",
        "                generos[genero] = []\n",
        "            generos[genero].append(id_musica)\n",
        "\n",
        "    # Listas para armazenar as músicas de treino, validação e teste\n",
        "    musicas_treino = []\n",
        "    musicas_validacao = []\n",
        "    musicas_teste = []\n",
        "\n",
        "    # Agora, vamos dividir as músicas por gênero em treino, validação e teste de forma aleatória\n",
        "    for genero, musicas in generos.items():\n",
        "        # Embaralha as músicas para aleatoriedade\n",
        "        random.shuffle(musicas)\n",
        "\n",
        "        # Verifica se há pelo menos 30 músicas para dividir\n",
        "        if len(musicas) >= 30:\n",
        "            # Divide as músicas de forma aleatória\n",
        "            treino = musicas[:21]\n",
        "            validacao = musicas[21:27]\n",
        "            teste = musicas[27:30]\n",
        "\n",
        "            # Adiciona as listas para cada categoria\n",
        "            musicas_treino.extend(treino)\n",
        "            musicas_validacao.extend(validacao)\n",
        "            musicas_teste.extend(teste)\n",
        "        else:\n",
        "            # Se houver menos de 30 músicas, podemos decidir o que fazer, mas aqui estamos ignorando as músicas\n",
        "            pass\n",
        "\n",
        "    # Retorna as 3 listas\n",
        "    return musicas_treino, musicas_validacao, musicas_teste"
      ],
      "metadata": {
        "id": "9j_nOG1e9W94"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "treino,validacao,teste = dividir_musicas_em_listas('/content/generos.xlsx',genders)"
      ],
      "metadata": {
        "id": "neDvYuGb9bHx"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in treino:\n",
        "  print(check_gender_by_id('/content/generos.xlsx',x,genders))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z1jih8o90tc",
        "outputId": "b5422e1e-6467-4084-bab3-64aedef46393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RSJULw20Yse7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/espectrogramas.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-q7bx-IYkXi",
        "outputId": "40dc13af-e6b4-444e-ef00-ca22be89ad81"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/espectrogramas.zip\n",
            "replace espectrogramas/238.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: espectrogramas/238.png  \n",
            "  inflating: espectrogramas/182.png  \n",
            "  inflating: espectrogramas/150.png  \n",
            "  inflating: espectrogramas/15.png   \n",
            "  inflating: espectrogramas/130.png  \n",
            "  inflating: espectrogramas/138.png  \n",
            "  inflating: espectrogramas/231.png  \n",
            "  inflating: espectrogramas/208.png  \n",
            "  inflating: espectrogramas/249.png  \n",
            "  inflating: espectrogramas/88.png   \n",
            "  inflating: espectrogramas/216.png  \n",
            "  inflating: espectrogramas/180.png  \n",
            "  inflating: espectrogramas/178.png  \n",
            "  inflating: espectrogramas/190.png  \n",
            "  inflating: espectrogramas/206.png  \n",
            "  inflating: espectrogramas/93.png   \n",
            "  inflating: espectrogramas/137.png  \n",
            "  inflating: espectrogramas/115.png  \n",
            "  inflating: espectrogramas/28.png   \n",
            "  inflating: espectrogramas/23.png   \n",
            "  inflating: espectrogramas/84.png   \n",
            "  inflating: espectrogramas/118.png  \n",
            "  inflating: espectrogramas/52.png   \n",
            "  inflating: espectrogramas/185.png  \n",
            "  inflating: espectrogramas/147.png  \n",
            "  inflating: espectrogramas/223.png  \n",
            "  inflating: espectrogramas/111.png  \n",
            "  inflating: espectrogramas/1.png    \n",
            "  inflating: espectrogramas/82.png   \n",
            "  inflating: espectrogramas/81.png   \n",
            "  inflating: espectrogramas/141.png  \n",
            "  inflating: espectrogramas/100.png  \n",
            "  inflating: espectrogramas/10.png   \n",
            "  inflating: espectrogramas/85.png   \n",
            "  inflating: espectrogramas/21.png   \n",
            "  inflating: espectrogramas/131.png  \n",
            "  inflating: espectrogramas/125.png  \n",
            "  inflating: espectrogramas/86.png   \n",
            "  inflating: espectrogramas/48.png   \n",
            "  inflating: espectrogramas/248.png  \n",
            "  inflating: espectrogramas/142.png  \n",
            "  inflating: espectrogramas/154.png  \n",
            "  inflating: espectrogramas/133.png  \n",
            "  inflating: espectrogramas/202.png  \n",
            "  inflating: espectrogramas/63.png   \n",
            "  inflating: espectrogramas/17.png   \n",
            "  inflating: espectrogramas/29.png   \n",
            "  inflating: espectrogramas/173.png  \n",
            "  inflating: espectrogramas/250.png  \n",
            "  inflating: espectrogramas/175.png  \n",
            "  inflating: espectrogramas/196.png  \n",
            "  inflating: espectrogramas/31.png   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo: Gêneros associados aos IDs\n",
        "id_to_genre = {\n",
        "    1: \"rock\",\n",
        "    2: \"pop\",\n",
        "    3: \"jazz\",\n",
        "    4: \"eletronical\",\n",
        "    5: \"classical\",\n",
        "    6: \"country\"\n",
        "    # Adicione todos os IDs e seus gêneros\n",
        "}\n",
        "\n",
        "# Converta os gêneros para índices numéricos para o treinamento\n",
        "genre_to_index = {genre: idx for idx, genre in enumerate(set(id_to_genre.values()))}\n",
        "\n",
        "# Exemplo: rock -> 0, pop -> 1, jazz -> 2\n",
        "id_to_label = {id: genre_to_index[genre] for id, genre in id_to_genre.items()}\n"
      ],
      "metadata": {
        "id": "UgWIruqaplcZ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "\n",
        "base_dir = \"/content/espectrogramas\"\n",
        "\n",
        "def id_to_filepath(id):\n",
        "  return os.path.join(base_dir,f\"{id}.png\")"
      ],
      "metadata": {
        "id": "p2G9EJ80XlH7"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/generos.xlsx')\n",
        "\n",
        "# Cria o mapeamento de gêneros para índices\n",
        "genre_to_index = {genre: idx for idx, genre in enumerate(set(df['genero']))}\n",
        "\n",
        "# Mapeia IDs das músicas aos índices das classes\n",
        "id_to_label = {row['id']: genre_to_index[row['genero']] for _, row in df.iterrows()}\n",
        "\n",
        "print(\"id_to_label:\", id_to_label)"
      ],
      "metadata": {
        "id": "J0k7ixp6sOQq",
        "outputId": "75a3df3c-e2a1-4c40-e3c3-ebd544d666ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id_to_label: {1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 6, 12: 6, 13: 6, 14: 6, 15: 6, 16: 6, 17: 6, 18: 6, 19: 6, 20: 6, 21: 7, 22: 7, 23: 7, 24: 7, 25: 7, 26: 7, 27: 7, 28: 7, 29: 7, 30: 7, 31: 4, 32: 4, 33: 4, 34: 4, 35: 4, 36: 4, 37: 4, 38: 4, 39: 4, 40: 4, 41: 2, 42: 2, 43: 2, 44: 2, 45: 2, 46: 2, 47: 2, 48: 2, 49: 2, 50: 2, 51: 5, 52: 5, 53: 5, 54: 5, 55: 5, 56: 5, 57: 5, 58: 5, 59: 5, 60: 5, 61: 3, 62: 3, 63: 3, 64: 3, 65: 3, 66: 3, 67: 3, 68: 3, 69: 3, 70: 3, 71: 10, 72: 10, 73: 10, 74: 10, 75: 10, 76: 10, 77: 10, 78: 10, 79: 10, 80: 10, 81: 0, 82: 0, 83: 0, 84: 0, 85: 0, 86: 0, 87: 0, 88: 0, 89: 0, 90: 0, 91: 8, 92: 8, 93: 8, 94: 8, 95: 8, 96: 8, 97: 8, 98: 8, 99: 8, 100: 8, 101: 9, 102: 9, 103: 9, 104: 9, 105: 9, 106: 9, 107: 9, 108: 9, 109: 9, 110: 9, 111: 1, 112: 1, 113: 1, 114: 1, 115: 1, 116: 1, 117: 1, 118: 1, 119: 1, 120: 1, 121: 1, 122: 1, 123: 1, 124: 1, 125: 1, 126: 1, 127: 1, 128: 1, 129: 1, 130: 1, 131: 6, 132: 6, 133: 6, 134: 6, 135: 6, 136: 6, 137: 6, 138: 6, 139: 6, 140: 6, 141: 6, 142: 6, 143: 6, 144: 6, 145: 6, 146: 6, 147: 6, 148: 6, 149: 6, 150: 6, 151: 4, 152: 4, 153: 4, 154: 4, 155: 4, 156: 4, 157: 4, 158: 4, 159: 4, 160: 4, 161: 4, 162: 4, 163: 4, 164: 4, 165: 4, 166: 4, 167: 4, 168: 4, 169: 4, 170: 4, 171: 2, 172: 2, 173: 2, 174: 2, 175: 2, 176: 2, 177: 2, 178: 2, 179: 2, 180: 2, 181: 2, 182: 2, 183: 2, 184: 2, 185: 2, 186: 2, 187: 2, 188: 2, 189: 2, 190: 2, 191: 5, 192: 5, 193: 5, 194: 5, 195: 5, 196: 5, 197: 5, 198: 5, 199: 5, 200: 5, 201: 5, 202: 5, 203: 5, 204: 5, 205: 5, 206: 5, 207: 5, 208: 5, 209: 5, 210: 5, 211: 0, 212: 0, 213: 0, 214: 0, 215: 0, 216: 0, 217: 0, 218: 0, 219: 0, 220: 0, 221: 0, 222: 0, 223: 0, 224: 0, 225: 0, 226: 0, 227: 0, 228: 0, 229: 0, 230: 0, 231: 8, 232: 8, 233: 8, 234: 8, 235: 8, 236: 8, 237: 8, 238: 8, 239: 8, 240: 8, 241: 8, 242: 8, 243: 8, 244: 8, 245: 8, 246: 8, 247: 8, 248: 8, 249: 8, 250: 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf_dataset_with_labels(id_list, id_to_label):\n",
        "    filepaths = [id_to_filepath(id) for id in id_list]\n",
        "    labels = [id_to_label[id] for id in id_list]\n",
        "\n",
        "    # Cria um dataset contendo pares (caminho, rótulo)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
        "\n",
        "    # Carrega a imagem e retorna (imagem, rótulo)\n",
        "    def load_image_and_label(filepath, label):\n",
        "        image = tf.io.read_file(filepath)\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "        image = tf.image.resize(image, [224, 224])  # Tamanho esperado pela CNN\n",
        "        return image, label\n",
        "\n",
        "    dataset = dataset.map(load_image_and_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "fzZv2aEkp-LD"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"IDs no treino:\", treino)\n",
        "print(\"IDs no val:\", validacao)\n",
        "print(\"IDs no teste:\", teste)\n",
        "\n",
        "# IDs presentes no dicionário de mapeamento\n",
        "print(\"IDs no id_to_label:\", list(id_to_label.keys()))"
      ],
      "metadata": {
        "id": "UrhQkamZqzrI",
        "outputId": "0c5e8bf6-e874-460c-de7a-f09db685cdcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDs no treino: [147, 137, 16, 13, 17, 146, 143, 15, 142, 145, 133, 14, 132, 131, 141, 139, 19, 135, 144, 18, 12, 168, 39, 151, 35, 34, 161, 155, 167, 152, 160, 163, 166, 165, 153, 170, 162, 169, 156, 157, 158, 33, 176, 171, 183, 180, 49, 186, 185, 190, 187, 42, 45, 177, 46, 189, 173, 182, 50, 41, 184, 44, 175, 197, 198, 57, 52, 60, 196, 59, 202, 204, 53, 201, 209, 192, 194, 200, 51, 210, 55, 191, 54, 199, 218, 89, 215, 213, 220, 81, 83, 217, 87, 90, 211, 224, 228, 230, 88, 86, 227, 212, 82, 225, 223, 250, 234, 238, 241, 232, 248, 92, 100, 246, 239, 99, 235, 236, 96, 245, 249, 91, 97, 247, 237, 242]\n",
            "IDs no val: [140, 20, 136, 148, 138, 149, 37, 164, 32, 38, 36, 154, 181, 174, 172, 188, 179, 47, 58, 203, 207, 193, 206, 56, 226, 214, 216, 221, 84, 219, 240, 94, 244, 231, 95, 98]\n",
            "IDs no teste: [150, 134, 11, 40, 31, 159, 178, 43, 48, 205, 195, 208, 85, 229, 222, 243, 233, 93]\n",
            "IDs no id_to_label: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = create_tf_dataset_with_labels(treino, id_to_label)\n",
        "val_dataset = create_tf_dataset_with_labels(validacao, id_to_label)\n",
        "test_dataset = create_tf_dataset_with_labels(teste, id_to_label)\n",
        "\n",
        "# Agrupar em lotes e otimizar\n",
        "batch_size = 32\n",
        "train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "NQukVDdAp_Ss"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "\n",
        "img = cv.imread(\"/content/espectrogramas/125.png\")\n",
        "\n",
        "\n",
        "input_shape = img.shape\n",
        "\n",
        "print(input_shape)"
      ],
      "metadata": {
        "id": "CHphZmmBvvSV",
        "outputId": "71d0666e-2849-4360-9bf9-13161628a34c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(924, 2325, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2))\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dropout(0.5))\n",
        "cnn.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
        "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-wHN_xuttVH_",
        "outputId": "259e7ee8-37f7-468f-fe0d-f6f4c7ec6006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'num_classes' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-61265333a7fc>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_classes' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "al5feFF0tUmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VdW1GUdgtUdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ipLMuBgRtUUG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}