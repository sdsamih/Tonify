{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Importação das bibliotecas**"
      ],
      "metadata": {
        "id": "M__QbgdQbHVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "OjvfXclHKudA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e92a1cb-94e0-4a67-c263-a478d4bed287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/trab_IA/dataset_espectro.zip"
      ],
      "metadata": {
        "id": "jJ5yOjZNK2j3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89c178d0-69d4-4fc7-caa6-72d3cc68583e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/trab_IA/dataset_espectro.zip\n",
            "   creating: dataset_espectro/\n",
            "   creating: dataset_espectro/test/\n",
            "   creating: dataset_espectro/test/Blues/\n",
            "  inflating: dataset_espectro/test/Blues/108.png  \n",
            "   creating: dataset_espectro/test/Classical/\n",
            "  inflating: dataset_espectro/test/Classical/59.png  \n",
            "   creating: dataset_espectro/test/Country/\n",
            "  inflating: dataset_espectro/test/Country/93.png  \n",
            "   creating: dataset_espectro/test/Eletronical/\n",
            "  inflating: dataset_espectro/test/Eletronical/47.png  \n",
            "   creating: dataset_espectro/test/Folk/\n",
            "  inflating: dataset_espectro/test/Folk/75.png  \n",
            "   creating: dataset_espectro/test/Hip Hop/\n",
            "  inflating: dataset_espectro/test/Hip Hop/62.png  \n",
            "   creating: dataset_espectro/test/Instrumental/\n",
            "  inflating: dataset_espectro/test/Instrumental/6.png  \n",
            "   creating: dataset_espectro/test/Jazz/\n",
            "  inflating: dataset_espectro/test/Jazz/87.png  \n",
            "   creating: dataset_espectro/test/Pop/\n",
            "  inflating: dataset_espectro/test/Pop/33.png  \n",
            "   creating: dataset_espectro/test/Rock/\n",
            "  inflating: dataset_espectro/test/Rock/14.png  \n",
            "   creating: dataset_espectro/test/Soul/\n",
            "  inflating: dataset_espectro/test/Soul/28.png  \n",
            "   creating: dataset_espectro/train/\n",
            "   creating: dataset_espectro/train/Blues/\n",
            "  inflating: dataset_espectro/train/Blues/101.png  \n",
            "  inflating: dataset_espectro/train/Blues/102.png  \n",
            "  inflating: dataset_espectro/train/Blues/103.png  \n",
            "  inflating: dataset_espectro/train/Blues/105.png  \n",
            "  inflating: dataset_espectro/train/Blues/107.png  \n",
            "  inflating: dataset_espectro/train/Blues/109.png  \n",
            "  inflating: dataset_espectro/train/Blues/110.png  \n",
            "   creating: dataset_espectro/train/Classical/\n",
            "  inflating: dataset_espectro/train/Classical/52.png  \n",
            "  inflating: dataset_espectro/train/Classical/53.png  \n",
            "  inflating: dataset_espectro/train/Classical/54.png  \n",
            "  inflating: dataset_espectro/train/Classical/55.png  \n",
            "  inflating: dataset_espectro/train/Classical/56.png  \n",
            "  inflating: dataset_espectro/train/Classical/57.png  \n",
            "  inflating: dataset_espectro/train/Classical/60.png  \n",
            "   creating: dataset_espectro/train/Country/\n",
            "  inflating: dataset_espectro/train/Country/100.png  \n",
            "  inflating: dataset_espectro/train/Country/91.png  \n",
            "  inflating: dataset_espectro/train/Country/94.png  \n",
            "  inflating: dataset_espectro/train/Country/95.png  \n",
            "  inflating: dataset_espectro/train/Country/96.png  \n",
            "  inflating: dataset_espectro/train/Country/97.png  \n",
            "  inflating: dataset_espectro/train/Country/99.png  \n",
            "   creating: dataset_espectro/train/Eletronical/\n",
            "  inflating: dataset_espectro/train/Eletronical/41.png  \n",
            "  inflating: dataset_espectro/train/Eletronical/42.png  \n",
            "  inflating: dataset_espectro/train/Eletronical/43.png  \n",
            "  inflating: dataset_espectro/train/Eletronical/45.png  \n",
            "  inflating: dataset_espectro/train/Eletronical/46.png  \n",
            "  inflating: dataset_espectro/train/Eletronical/48.png  \n",
            "  inflating: dataset_espectro/train/Eletronical/50.png  \n",
            "   creating: dataset_espectro/train/Folk/\n",
            "  inflating: dataset_espectro/train/Folk/71.png  \n",
            "  inflating: dataset_espectro/train/Folk/72.png  \n",
            "  inflating: dataset_espectro/train/Folk/73.png  \n",
            "  inflating: dataset_espectro/train/Folk/76.png  \n",
            "  inflating: dataset_espectro/train/Folk/77.png  \n",
            "  inflating: dataset_espectro/train/Folk/78.png  \n",
            "  inflating: dataset_espectro/train/Folk/79.png  \n",
            "   creating: dataset_espectro/train/Hip Hop/\n",
            "  inflating: dataset_espectro/train/Hip Hop/63.png  \n",
            "  inflating: dataset_espectro/train/Hip Hop/65.png  \n",
            "  inflating: dataset_espectro/train/Hip Hop/66.png  \n",
            "  inflating: dataset_espectro/train/Hip Hop/67.png  \n",
            "  inflating: dataset_espectro/train/Hip Hop/68.png  \n",
            "  inflating: dataset_espectro/train/Hip Hop/69.png  \n",
            "  inflating: dataset_espectro/train/Hip Hop/70.png  \n",
            "   creating: dataset_espectro/train/Instrumental/\n",
            "  inflating: dataset_espectro/train/Instrumental/1.png  \n",
            "  inflating: dataset_espectro/train/Instrumental/2.png  \n",
            "  inflating: dataset_espectro/train/Instrumental/3.png  \n",
            "  inflating: dataset_espectro/train/Instrumental/4.png  \n",
            "  inflating: dataset_espectro/train/Instrumental/7.png  \n",
            "  inflating: dataset_espectro/train/Instrumental/8.png  \n",
            "  inflating: dataset_espectro/train/Instrumental/9.png  \n",
            "   creating: dataset_espectro/train/Jazz/\n",
            "  inflating: dataset_espectro/train/Jazz/81.png  \n",
            "  inflating: dataset_espectro/train/Jazz/83.png  \n",
            "  inflating: dataset_espectro/train/Jazz/85.png  \n",
            "  inflating: dataset_espectro/train/Jazz/86.png  \n",
            "  inflating: dataset_espectro/train/Jazz/88.png  \n",
            "  inflating: dataset_espectro/train/Jazz/89.png  \n",
            "  inflating: dataset_espectro/train/Jazz/90.png  \n",
            "   creating: dataset_espectro/train/Pop/\n",
            "  inflating: dataset_espectro/train/Pop/31.png  \n",
            "  inflating: dataset_espectro/train/Pop/35.png  \n",
            "  inflating: dataset_espectro/train/Pop/36.png  \n",
            "  inflating: dataset_espectro/train/Pop/37.png  \n",
            "  inflating: dataset_espectro/train/Pop/38.png  \n",
            "  inflating: dataset_espectro/train/Pop/39.png  \n",
            "  inflating: dataset_espectro/train/Pop/40.png  \n",
            "   creating: dataset_espectro/train/Rock/\n",
            "  inflating: dataset_espectro/train/Rock/11.png  \n",
            "  inflating: dataset_espectro/train/Rock/12.png  \n",
            "  inflating: dataset_espectro/train/Rock/13.png  \n",
            "  inflating: dataset_espectro/train/Rock/15.png  \n",
            "  inflating: dataset_espectro/train/Rock/17.png  \n",
            "  inflating: dataset_espectro/train/Rock/19.png  \n",
            "  inflating: dataset_espectro/train/Rock/20.png  \n",
            "   creating: dataset_espectro/train/Soul/\n",
            "  inflating: dataset_espectro/train/Soul/22.png  \n",
            "  inflating: dataset_espectro/train/Soul/23.png  \n",
            "  inflating: dataset_espectro/train/Soul/25.png  \n",
            "  inflating: dataset_espectro/train/Soul/26.png  \n",
            "  inflating: dataset_espectro/train/Soul/27.png  \n",
            "  inflating: dataset_espectro/train/Soul/29.png  \n",
            "  inflating: dataset_espectro/train/Soul/30.png  \n",
            "   creating: dataset_espectro/val/\n",
            "   creating: dataset_espectro/val/Blues/\n",
            "  inflating: dataset_espectro/val/Blues/104.png  \n",
            "  inflating: dataset_espectro/val/Blues/106.png  \n",
            "   creating: dataset_espectro/val/Classical/\n",
            "  inflating: dataset_espectro/val/Classical/51.png  \n",
            "  inflating: dataset_espectro/val/Classical/58.png  \n",
            "   creating: dataset_espectro/val/Country/\n",
            "  inflating: dataset_espectro/val/Country/92.png  \n",
            "  inflating: dataset_espectro/val/Country/98.png  \n",
            "   creating: dataset_espectro/val/Eletronical/\n",
            "  inflating: dataset_espectro/val/Eletronical/44.png  \n",
            "  inflating: dataset_espectro/val/Eletronical/49.png  \n",
            "   creating: dataset_espectro/val/Folk/\n",
            "  inflating: dataset_espectro/val/Folk/74.png  \n",
            "  inflating: dataset_espectro/val/Folk/80.png  \n",
            "   creating: dataset_espectro/val/Hip Hop/\n",
            "  inflating: dataset_espectro/val/Hip Hop/61.png  \n",
            "  inflating: dataset_espectro/val/Hip Hop/64.png  \n",
            "   creating: dataset_espectro/val/Instrumental/\n",
            "  inflating: dataset_espectro/val/Instrumental/10.png  \n",
            "  inflating: dataset_espectro/val/Instrumental/5.png  \n",
            "   creating: dataset_espectro/val/Jazz/\n",
            "  inflating: dataset_espectro/val/Jazz/82.png  \n",
            "  inflating: dataset_espectro/val/Jazz/84.png  \n",
            "   creating: dataset_espectro/val/Pop/\n",
            "  inflating: dataset_espectro/val/Pop/32.png  \n",
            "  inflating: dataset_espectro/val/Pop/34.png  \n",
            "   creating: dataset_espectro/val/Rock/\n",
            "  inflating: dataset_espectro/val/Rock/16.png  \n",
            "  inflating: dataset_espectro/val/Rock/18.png  \n",
            "   creating: dataset_espectro/val/Soul/\n",
            "  inflating: dataset_espectro/val/Soul/21.png  \n",
            "  inflating: dataset_espectro/val/Soul/24.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Criação da Rede Neural Convolucional**"
      ],
      "metadata": {
        "id": "eLg84m-PmO-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Inicializando a CNN**"
      ],
      "metadata": {
        "id": "vILAF-ocmbkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "u2YYZv77q4FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pré-processamento\n"
      ],
      "metadata": {
        "id": "2owh3j8H7aE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/dataset_espectro/train\"\n",
        "test_dir = \"/content/dataset_espectro/test\"\n",
        "val_dir = \"/content/dataset_espectro/val\""
      ],
      "metadata": {
        "id": "6v7B4Jse4GYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255)"
      ],
      "metadata": {
        "id": "ad37kWGz7Xwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(400,1000),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sVeMJMq8I5b",
        "outputId": "3ed4d3fe-25bb-46d6-b7b5-dfdb249324a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 77 images belonging to 11 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_gen = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(400,1000),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPr0miFr8mEf",
        "outputId": "ea5f505e-3959-461b-931d-85c94493ac71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22 images belonging to 11 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(400,1000),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BALIyka081rV",
        "outputId": "572c6e21-ea58-4a10-9e96-12fb4d408e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11 images belonging to 11 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = [400,1000,3]\n",
        "num_classes = len(train_gen.class_indices)"
      ],
      "metadata": {
        "id": "Na84xJyB9K5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##O modelo em si\n"
      ],
      "metadata": {
        "id": "oPaDmL-q7gqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "Vi7PnE9Tmfs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2))"
      ],
      "metadata": {
        "id": "3iT0CsrPmmeJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e2a9e9-8880-4715-d0c6-9008e20560d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2))"
      ],
      "metadata": {
        "id": "0awa2J5lmy22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2))"
      ],
      "metadata": {
        "id": "XwX7cOm2tiVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "HZ11geN3nBCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dropout(0.5))"
      ],
      "metadata": {
        "id": "Y_4ub3XBnGaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "rv5CM5qat5ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nTtHnSYEoLZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Treinando a CNN e estimando no conjunto de testes**"
      ],
      "metadata": {
        "id": "Ewn2dEtao0la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = cnn.fit(train_gen, epochs=30, validation_data=val_gen)"
      ],
      "metadata": {
        "id": "4jNTpdsLoQxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75541f1a-a736-41d4-8cd9-487eca709e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 36s/step - accuracy: 0.1189 - loss: 39.5148 - val_accuracy: 0.0909 - val_loss: 14.1094\n",
            "Epoch 2/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 25s/step - accuracy: 0.0637 - loss: 16.3326 - val_accuracy: 0.0909 - val_loss: 2.4451\n",
            "Epoch 3/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 35s/step - accuracy: 0.0491 - loss: 2.6196 - val_accuracy: 0.0909 - val_loss: 2.3553\n",
            "Epoch 4/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 35s/step - accuracy: 0.1622 - loss: 2.3842 - val_accuracy: 0.0909 - val_loss: 2.3484\n",
            "Epoch 5/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 35s/step - accuracy: 0.1425 - loss: 2.3301 - val_accuracy: 0.0909 - val_loss: 2.2953\n",
            "Epoch 6/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 26s/step - accuracy: 0.1685 - loss: 2.1613 - val_accuracy: 0.2727 - val_loss: 2.2871\n",
            "Epoch 7/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 26s/step - accuracy: 0.2581 - loss: 2.0095 - val_accuracy: 0.2273 - val_loss: 2.2197\n",
            "Epoch 8/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 25s/step - accuracy: 0.3524 - loss: 1.7990 - val_accuracy: 0.2727 - val_loss: 2.1360\n",
            "Epoch 9/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 26s/step - accuracy: 0.4799 - loss: 1.5590 - val_accuracy: 0.3182 - val_loss: 2.1345\n",
            "Epoch 10/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 25s/step - accuracy: 0.3696 - loss: 1.6456 - val_accuracy: 0.1818 - val_loss: 2.2433\n",
            "Epoch 11/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 34s/step - accuracy: 0.6035 - loss: 1.2472 - val_accuracy: 0.2727 - val_loss: 2.1371\n",
            "Epoch 12/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 35s/step - accuracy: 0.5602 - loss: 1.3336 - val_accuracy: 0.1364 - val_loss: 2.5075\n",
            "Epoch 13/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 34s/step - accuracy: 0.6410 - loss: 0.9941 - val_accuracy: 0.2273 - val_loss: 2.8887\n",
            "Epoch 14/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 35s/step - accuracy: 0.7374 - loss: 0.9099 - val_accuracy: 0.1818 - val_loss: 2.5349\n",
            "Epoch 15/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 35s/step - accuracy: 0.6832 - loss: 1.1379 - val_accuracy: 0.2727 - val_loss: 2.2727\n",
            "Epoch 16/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25s/step - accuracy: 0.7893 - loss: 0.7964 - val_accuracy: 0.4091 - val_loss: 2.3081\n",
            "Epoch 17/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 28s/step - accuracy: 0.7022 - loss: 0.7792 - val_accuracy: 0.4545 - val_loss: 2.3404\n",
            "Epoch 18/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 34s/step - accuracy: 0.7309 - loss: 0.7203 - val_accuracy: 0.3182 - val_loss: 2.5117\n",
            "Epoch 19/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 34s/step - accuracy: 0.8943 - loss: 0.4824 - val_accuracy: 0.2273 - val_loss: 2.5750\n",
            "Epoch 20/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 25s/step - accuracy: 0.8770 - loss: 0.4423 - val_accuracy: 0.3182 - val_loss: 2.6530\n",
            "Epoch 21/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 34s/step - accuracy: 0.8945 - loss: 0.3467 - val_accuracy: 0.3182 - val_loss: 2.8368\n",
            "Epoch 22/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 26s/step - accuracy: 0.8048 - loss: 0.4232 - val_accuracy: 0.2727 - val_loss: 3.4906\n",
            "Epoch 23/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 28s/step - accuracy: 0.8395 - loss: 0.6486 - val_accuracy: 0.3636 - val_loss: 2.8191\n",
            "Epoch 24/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 36s/step - accuracy: 0.9122 - loss: 0.4412 - val_accuracy: 0.3182 - val_loss: 2.8165\n",
            "Epoch 25/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 25s/step - accuracy: 0.8972 - loss: 0.4097 - val_accuracy: 0.3182 - val_loss: 3.0547\n",
            "Epoch 26/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 26s/step - accuracy: 0.8895 - loss: 0.3263 - val_accuracy: 0.2727 - val_loss: 3.5364\n",
            "Epoch 27/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25s/step - accuracy: 0.9473 - loss: 0.1784 - val_accuracy: 0.3182 - val_loss: 4.0412\n",
            "Epoch 28/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 26s/step - accuracy: 0.9154 - loss: 0.2506 - val_accuracy: 0.3182 - val_loss: 4.3104\n",
            "Epoch 29/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 25s/step - accuracy: 0.9274 - loss: 0.2057 - val_accuracy: 0.3182 - val_loss: 4.1862\n",
            "Epoch 30/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 25s/step - accuracy: 0.9610 - loss: 0.1189 - val_accuracy: 0.2273 - val_loss: 4.0148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = cnn.evaluate(test_gen)\n",
        "print(f\"Perda nos dados de teste: {test_loss}\")\n",
        "print(f\"Acurácia nos dados de teste: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "4FMd-MrZ99IT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "7da0c09e-78a7-498b-d155-77ef701547e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cnn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ae98a5650747>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Perda nos dados de teste: {test_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Acurácia nos dados de teste: {test_accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cnn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processar a imagem\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "test_image = image.load_img(\"/content/dataset_espectro/test/Eletronical/47.png\", target_size=(400, 1000))  # Tamanho da imagem usado no treinamento\n",
        "test_image = image.img_to_array(test_image)  # Converte a imagem para um array NumPy\n",
        "test_image = np.expand_dims(test_image, axis=0)  # Adiciona uma dimensão para o batch\n",
        "test_image = test_image"
      ],
      "metadata": {
        "id": "2Yhz5jq_Mw5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = cnn.predict(test_image)\n",
        "\n",
        "print(f\"Result: {result}\")\n",
        "\n",
        "predicted_class_index = np.argmax(result)  # Obtém o índice da classe com maior probabilidade\n",
        "print(f\"Predicted class index: {predicted_class_index}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY5o-Og4NIxF",
        "outputId": "852065dd-38d6-493e-ef4e-b253d290c5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step\n",
            "Result: [[1.0000000e+00 0.0000000e+00 3.3637510e-26 2.7023976e-25 0.0000000e+00\n",
            "  6.4744788e-27 4.5108618e-16 0.0000000e+00 4.1161588e-12 3.1795836e-29\n",
            "  8.2470836e-11]]\n",
            "Predicted class index: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dicionário de classes (gerado no treinamento)\n",
        "class_indices = {'rock': 0, 'jazz': 1, 'pop': 2, 'hip hop':3,'blues':4,'classical':5,'country':6,'eletronical':7,'folk':8,'instrumental':9,'soul':10}  # Substitua com as classes reais do treinamento\n",
        "index_to_class = {v: k for k, v in class_indices.items()}  # Converte índice para nome da classe\n",
        "\n",
        "# Obter o nome da classe prevista\n",
        "prediction = index_to_class[predicted_class_index]\n",
        "\n",
        "# Exibir o resultado\n",
        "print(f\"Predição: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ne6zns2NpqB",
        "outputId": "3baee4f5-44c5-41dd-8a66-7212d63d41f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predição: rock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função para receber o gênero de uma música do dataset de acordo com seu ID"
      ],
      "metadata": {
        "id": "beC8RuTq3r4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def check_gender_by_id(filename, id, genders) -> None | str:\n",
        "    df = pd.read_excel(filename)\n",
        "\n",
        "    genero = df.loc[df['id'] == id, 'genero']\n",
        "\n",
        "    if not genero.empty:\n",
        "        if genero.iloc[0] in genders:\n",
        "            return genero.iloc[0]\n",
        "        else:\n",
        "            return None\n",
        "    else:\n",
        "        return \"ID not found\""
      ],
      "metadata": {
        "id": "ZzsmvSSe32Dq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de uso\n",
        "arquivo = '/content/generos.xlsx'\n",
        "id_musica = 17  # Coloque o ID desejado\n",
        "genders = ['Rock', 'Jazz', 'Pop', 'Classical', 'Country', 'Eletronical']\n",
        "genero = check_gender_by_id(arquivo, id_musica, genders)\n",
        "print(f'O gênero da música com ID {id_musica} é: {genero}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTaTYkMQ51hM",
        "outputId": "a5c9f918-27b7-4368-dea9-2d5d99972750"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O gênero da música com ID 17 é: Rock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dividir_musicas_em_listas(arquivo_xlsx, generos_validos):\n",
        "    # Carrega o arquivo Excel para um DataFrame\n",
        "    df = pd.read_excel(arquivo_xlsx)\n",
        "\n",
        "    # Dicionário para armazenar as músicas de cada gênero\n",
        "    generos = {}\n",
        "\n",
        "    # Itera por todas as músicas no arquivo\n",
        "    for id_musica in df['id']:\n",
        "        # Usa a função check_gender_by_id para obter o gênero da música\n",
        "        genero = check_gender_by_id(arquivo_xlsx, id_musica, generos_validos)\n",
        "\n",
        "        # Se o gênero for válido (não None e dentro da lista de gêneros válidos), adiciona o ID\n",
        "        if genero and genero in generos_validos:\n",
        "            if genero not in generos:\n",
        "                generos[genero] = []\n",
        "            generos[genero].append(id_musica)\n",
        "\n",
        "    # Listas para armazenar as músicas de treino, validação e teste\n",
        "    musicas_treino = []\n",
        "    musicas_validacao = []\n",
        "    musicas_teste = []\n",
        "\n",
        "    # Agora, vamos dividir as músicas por gênero em treino, validação e teste de forma aleatória\n",
        "    for genero, musicas in generos.items():\n",
        "        # Embaralha as músicas para aleatoriedade\n",
        "        random.shuffle(musicas)\n",
        "\n",
        "        # Verifica se há pelo menos 30 músicas para dividir\n",
        "        if len(musicas) >= 30:\n",
        "            # Divide as músicas de forma aleatória\n",
        "            treino = musicas[:21]\n",
        "            validacao = musicas[21:27]\n",
        "            teste = musicas[27:30]\n",
        "\n",
        "            # Adiciona as listas para cada categoria\n",
        "            musicas_treino.extend(treino)\n",
        "            musicas_validacao.extend(validacao)\n",
        "            musicas_teste.extend(teste)\n",
        "        else:\n",
        "            # Se houver menos de 30 músicas, podemos decidir o que fazer, mas aqui estamos ignorando as músicas\n",
        "            pass\n",
        "\n",
        "    # Retorna as 3 listas\n",
        "    return musicas_treino, musicas_validacao, musicas_teste"
      ],
      "metadata": {
        "id": "9j_nOG1e9W94"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "treino,validacao,teste = dividir_musicas_em_listas('/content/generos.xlsx',genders)"
      ],
      "metadata": {
        "id": "neDvYuGb9bHx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in treino:\n",
        "  print(check_gender_by_id('/content/generos.xlsx',x,genders))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z1jih8o90tc",
        "outputId": "9a22ebcd-458e-4a65-8099-82a09db71e57"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Rock\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Pop\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Eletronical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Classical\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Jazz\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n",
            "Country\n"
          ]
        }
      ]
    }
  ]
}